jobName: HiveToHive
engine: spark
job:
  - input:
      df-name: etl_framework_source_one
      type: hive
      identifier: hive
      table: etl_framework_source_one
      schema: sdf_schema

  - input:
        df-name: etl_framework_source_two
        type: hive
        identifier: hive
        table: etl_framework_source_two
        schema: sdf_schema

  - transform:
      df-name: t1
      t_inputs: etl_framework_source_one,etl_framework_source_two
      query: "select
              x.id as id,
              x.first_name as x_first_name,
              x.last_name as x_last_name,
              x.cardnumber as x_cardnumber,
              x.accountnumber as x_accountnumber,
              y.first_name as y_first_name,
              y.last_name as y_last_name,
              y.cardnumber as y_cardnumber,
              y.accountnumber as y_accountnumber
              from sdf_framework_source_one x
              left join sdf_framework_source_two y
              on x.id=y.id"
      output: out-01

# No need to mention the partition as SDF will be able to identify the partition from the table
# if it is present and willload the data accordingly.
# If table is not partitioned SDF will load the data as non partitioned table
  - output:
      df-name: out-01
      type: hive
      identifier: hive
      table: spark_sdf_join #Partitioned by id
      schema: sdf_schema
      mode: overwrite
